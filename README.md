# ğŸ“ SnapClass.AI - AI-Powered Educational Assistant

SnapClass.AI is a fully Offline intelligent educational platform that combines multiple AI models to process, analyze, and generate educational content from various input sources including audio, PDFs, and text.

## ğŸ—ï¸ Project Architecture

```
SnapClass/
â”œâ”€â”€ ğŸ“ server/                    # Main application backend
â”‚   â”œâ”€â”€ ğŸš€ desktop_app.py        # Main GUI application (PyQt5/Tkinter)
â”‚   â”œâ”€â”€ ğŸŒ app.py                # Flask web server
|   â”œâ”€â”€ ğŸŒ desktop_app.py
|   â”œâ”€â”€ ğŸŒ chat.py
â”‚   â”œâ”€â”€ ğŸ”„ trans.py              # Main processing orchestrator
â”‚   â”œâ”€â”€ ğŸ¤ stt.py                # Speech-to-Text (Whisper)
â”‚   â”œâ”€â”€ ğŸ“„ pdf_reader.py         # PDF processing (Nougat + BLIP)
â”‚   â”œâ”€â”€ â“ question_gen.py        # Question generation (LLaMA)
â”‚   â”œâ”€â”€ ğŸ“Š slm_analyse.py        # Student analysis (LLaMA)
â”‚   â”œâ”€â”€ ğŸ› ï¸ utils.py              # Utility functions
â”‚   â”œâ”€â”€ âš™ï¸ setup.py              # Model downloader
â”‚   â”œâ”€â”€ ğŸ“ templates/            # HTML templates
â”‚   â”œâ”€â”€ ğŸ¨ static/               # CSS/JS assets
â”‚   â”œâ”€â”€ ğŸ“ uploads/              # User file uploads
â”‚   â””â”€â”€ ğŸ“ output/               # Processed results
â”‚   â”œâ”€â”€ ğŸ“ llama3/               # LLaMA 3.2 3B model
â”‚   â”‚   â”œâ”€â”€ genie-t2t-run.exe    # Genie inference engine
â”‚   â”‚   â”œâ”€â”€ genie_config.json    # Model configuration
â”‚   â”‚   â”œâ”€â”€ *.bin                # Model weights (3 parts)
â”‚   â”‚   â””â”€â”€ *.dll                # Windows dependencies
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ whisper/              # OpenAI Whisper model
â”‚   â”‚   â”œâ”€â”€ model.safetensors    # Speech recognition model
â”‚   â”‚   â”œâ”€â”€ tokenizer.json       # Tokenizer
â”‚   â”‚   â””â”€â”€ config.json          # Model configuration
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ poppler/              # PDF processing utilities
â”‚
â””â”€â”€ ğŸ“‹ requirements.txt           # Python dependencies
```

## ğŸš€ Key Features

### ğŸ¯ **Multi-Modal AI Processing**
- **Audio Processing**: Speech-to-text conversion using Whisper
- **Document Processing**: PDF text extraction module
- **Text Generation**: Question generation and analysis using LLaMA 3.2

### ğŸ–¥ï¸ **Dual Interface**
- **Desktop Application**: Native GUI built with customtkinter
- **Web Interface**: Flask-based web server with React frontend

### ğŸ”„ **Workflow Pipeline**
1. **Input Processing**: Audio files, PDFs, or text input
2. **AI Analysis**: Multi-model AI processing pipeline
3. **Content Generation**: Questions, summaries, and insights
4. **Output Delivery**: Structured results via GUI or web interface

## ğŸ› ï¸ Technology Stack

### **Backend (Python)**
- **Framework**: Flask (web server)
- **GUI**: customtkinter (desktop app)
- **AI/ML**: PyTorch, Transformers, Whisper, Llama3.2
- **Audio**: librosa, soundfile
- **PDF**: pytesseract, pypdf
- **Data**: numpy, PIL, PyYAML


### **AI Models**
- **LLaMA 3.2 3B**: Text generation and analysis
- **Whisper**: Speech-to-text transcription

## ğŸ“‹ Prerequisites

### **System Requirements**
- **OS**: Windows 10/11, macOS, or Linux
- **Processor**: Snapdragon X Elite
- **RAM**: Minimum 8GB, Recommended 16GB+
- **Storage**: 10GB+ free space for models
- **GPU**: Optional but recommended for faster inference

### **Software Requirements**
- **Python**: 3.8 - 3.11
- **Git**: For version control

## ğŸš€ Installation & Setup

### **1. Clone Repository**
```bash
git clone https://github.com/YOUR_USERNAME/SnapClass.git
cd SnapClass
```

### **2. Python Environment Setup**
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### **3. Model Setup**
```bash
# Navigate to server directory
cd server

# Download and setup AI models
python setup.py
```
Dwonload NPU optimised Llama3.2 model [Click here](https://drive.google.com/drive/folders/1TfiNrZJoCg5KLYPmiixiKVCDCU2RyWw1?usp=drive_link)
Download poppler from [here](https://drive.google.com/drive/folders/1Uiy7IQCcPGxjNv6xnyAoFE6zhR81HFH5?usp=sharing)
**Note**: This will download ~5GB of AI models. Ensure stable internet connection.

## ğŸ¯ Usage

### **Desktop Application**
```bash
cd server
python desktop_app.py
```

## ğŸ”§ Configuration

### **Model Configuration**
- **LLaMA**: Edit `server/llama3/genie_config.json`
- **Whisper**: Configure in `server/whisper/config.json`
- **Nougat**: Settings in `server/nougat/config.json`
- **BLIP**: Options in `server/blip/config.json`

## ğŸ“¦ Building Executable and Msix

### **Using PyInstaller**
```bash
# Use MSIX build script
.\build.ps1 -Version "1.0.0.0" -Publisher "CN=SnapClass.A"
```

## ğŸ› Troubleshooting

#### **Model Loading Errors**
```bash
# Verify model files exist
ls -la server/llama3/
ls -la server/whisper/
```

#### **Memory Issues**
- Reduce batch sizes in model configurations
- Use CPU-only inference for lower memory usage
- Close other applications to free RAM
- Check the availability of Snapdragon NPU

#### **Import Errors**
```bash
# Reinstall dependencies
pip uninstall -r requirements.txt
pip install -r requirements.txt
```

### **Performance Optimization**
- **GPU Acceleration**: Install CUDA-enabled PyTorch
- **Model Quantization**: Use quantized models for faster inference
- **Batch Processing**: Process multiple files simultaneously

## ğŸ¤ Contributing

### **Development Setup**
1. Fork the repository
2. Create feature branch: `git checkout -b feature-name`
3. Make changes and test thoroughly
4. Commit: `git commit -m 'Add feature'`
5. Push: `git push origin feature-name`
6. Create Pull Request

### **Code Style**
- **Python**: Follow PEP 8 guidelines
- **Documentation**: Update README for new features

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Meta AI**: LLaMA 3.2 model
- **OpenAI**: Whisper speech recognition
- **Open Source Community**: Various libraries and tools

## ğŸ“ Support
- A T Abbilaash (abbilaashat@gmail.com)

**Made with â¤ï¸ for the educational community**
